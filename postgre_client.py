import psycopg2
from sqlalchemy import create_engine, text, MetaData, Table
from urllib.parse import quote_plus
import pandas as pd

POSTGRES_CONFIG = {
    'host': 'postgre.cluster-cavkqwqmyvuw.us-west-2.rds.amazonaws.com',  # æ›¿æ¢ä¸ºå®é™…çš„PostgreSQLä¸»æœº
    'port': 5432,  # PostgreSQLé»˜è®¤ç«¯å£
    'database': 'postgres',
    'user': 'owpostgre',
    'password': 'oceanwing-pg02',
    'client_encoding': 'utf8',
    'autocommit': False,
    'connect_timeout': 30
}

TABLES = {
    'ASIN_goal_philips': 'ods_asin_goal_philips',
    'ods_category': 'ods_category',
    'ods_asin_philips': 'ods_asin_philips',
    'SI_keyword_philips': 'ods_si_keyword_philips',
    'ods_goal_vcp': 'ods_goal_vcp',
    'ods_asin_sale_goal': 'ods_asin_sale_goal',
    'ods_date_event': 'ods_date_even',
    'ods_category_dsp': 'ods_category_dsp',
}

def get_engine():
    """åˆ›å»ºPostgreSQLæ•°æ®åº“è¿æ¥"""
    password_encoded = quote_plus(POSTGRES_CONFIG['password'])
    connection_string = f"postgresql+psycopg2://{POSTGRES_CONFIG['user']}:{password_encoded}@{POSTGRES_CONFIG['host']}:{POSTGRES_CONFIG['port']}/{POSTGRES_CONFIG['database']}"
    return create_engine(connection_string)

def get_table_columns( table_name, database):
    """è·å–æ•°æ®åº“è¡¨çš„åˆ—å"""
    try:
        query = text(f"""SELECT column_name name
FROM information_schema.columns
WHERE table_name = '{table_name}'
ORDER BY ordinal_position """)
        with get_engine().begin() as conn:
            result = pd.read_sql(query, conn)
        return result['name'].tolist() if not result.empty else []
    except Exception as e:
        print(f'è·å–è¡¨ç»“æ„å¤±è´¥: {str(e)}')
        raise e

def to_postgresql_data(table_name, upload_mode, df, batch_size=1000):
    """ä¼˜åŒ–çš„åˆ†æ‰¹æ’å…¥ç‰ˆæœ¬ - PostgreSQLé€‚é…"""
    # try:
    #     to_mysql_data_safe(table_name, upload_mode, df)
    #     return True
    # except Exception as e:
    #     print(f"å®‰å…¨æ’å…¥å¤±è´¥: {e}")

    engine = get_engine()
    table_name = TABLES[table_name]

    # å°†åˆ—åè½¬ä¸ºå°å†™
    df.columns = df.columns.str.lower()
    if 'ods_date_even' in table_name :
        if 'date' in df.columns:
            df = df.rename(columns={'date': 'date_time'})
    # å¤„ç†æ›¿æ¢æ¨¡å¼ - PostgreSQLä½¿ç”¨TRUNCATEæˆ–DELETE
    if upload_mode == 'replace':
        with engine.begin() as conn:
            try:
                # PostgreSQLçš„TRUNCATEè¯­æ³•
                conn.execute(text(f"TRUNCATE TABLE {table_name}"))
                print(f"å·²æ¸…ç©ºè¡¨ {table_name}")
            except Exception as e:
                print(f"TRUNCATEå¤±è´¥ï¼Œä½¿ç”¨DELETE: {e}")
                conn.rollback()
                conn.execute(text(f"DELETE FROM {table_name}"))

    # åˆ†æ‰¹æ’å…¥æ•°æ®
    total_rows = len(df)
    inserted = 0

    for i in range(0, total_rows, batch_size):
        batch_df = df.iloc[i:i + batch_size]

        try:
            # æ¯ä¸ªæ‰¹æ¬¡ä½¿ç”¨ç‹¬ç«‹çš„äº‹åŠ¡
            with engine.begin() as conn:
                # PostgreSQLä¸éœ€è¦è®¾ç½®innodb_lock_wait_timeout
                # å¯ä»¥è®¾ç½®è¯­å¥è¶…æ—¶ï¼ˆå¯é€‰ï¼‰
                conn.execute(text("SET statement_timeout = 300000"))  # 300ç§’

                batch_df.to_sql(
                    table_name,
                    conn,
                    if_exists='append',
                    index=False,
                    method='multi',
                    chunksize=1000
                )

            inserted += len(batch_df)
            print(f"å·²æ’å…¥ {inserted}/{total_rows} è¡Œ")

        except Exception as e:
            print(f"æ’å…¥ç¬¬{i}-{min(i + batch_size, total_rows) - 1}è¡Œæ—¶å¤±è´¥: {e}")
            raise

    print(f"æ•°æ®ä¸Šä¼ å®Œæˆï¼Œå…±æ’å…¥ {total_rows} è¡Œ")
    return True

def to_mysql_data_safe(table_name, upload_mode, df):
    """å®‰å…¨çš„æ‰¹é‡æ’å…¥ - PostgreSQLé€‚é…"""
    engine = get_engine()
    table_name = TABLES[table_name]

    with engine.connect() as conn:
        # PostgreSQLè®¾ç½®è¯­å¥è¶…æ—¶
        conn.execute(text("SET statement_timeout = 300000"))

        if upload_mode == 'replace':
            try:
                # PostgreSQL TRUNCATEä¸éœ€è¦ç¦ç”¨å¤–é”®æ£€æŸ¥
                conn.execute(text(f"TRUNCATE TABLE {table_name}"))
                print(f"å·²æ¸…ç©ºè¡¨: {table_name}")
            except Exception as e:
                print(f"TRUNCATEå¤±è´¥ï¼Œä½¿ç”¨DELETE: {e}")
                conn.rollback()
                conn.execute(text(f"DELETE FROM {table_name}"))

        # å°†åˆ—åè½¬ä¸ºå°å†™
        df.columns = df.columns.str.lower()

        # å‡†å¤‡æ’å…¥SQL - ä½¿ç”¨PostgreSQLçš„å ä½ç¬¦%sï¼ˆä¸MySQLç›¸åŒï¼‰
        columns = ', '.join(df.columns)
        placeholders = ', '.join(['%s'] * len(df.columns))
        sql = f"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})"

        # åˆ†æ‰¹æ’å…¥
        batch_size = 100
        data = [tuple(x) for x in df.itertuples(index=False, name=None)]
        total_rows = len(data)

        for i in range(0, total_rows, batch_size):
            batch_data = data[i:i + batch_size]

            try:
                # ä½¿ç”¨executemanyæ‰¹é‡æ’å…¥
                with conn.connection.cursor() as cursor:
                    cursor.executemany(sql, batch_data)
                    conn.connection.commit()

                print(f"âœ… å·²æ’å…¥ {min(i + batch_size, total_rows)}/{total_rows} è¡Œ")

            except Exception as e:
                print(f"âŒâŒ æ‰¹æ¬¡æ’å…¥å¤±è´¥: {e}")
                # å°è¯•å•è¡Œæ’å…¥
                for row_data in batch_data:
                    try:
                        with conn.connection.cursor() as cursor:
                            cursor.execute(sql, row_data)
                            conn.connection.commit()
                    except Exception as single_error:
                        print(f"å•è¡Œæ’å…¥å¤±è´¥: {single_error}")
                        continue

    print(f"ğŸ‰ğŸ‰ æ•°æ®ä¸Šä¼ å®Œæˆï¼Œå…±æ’å…¥ {total_rows} è¡Œ")
    return True