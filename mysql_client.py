from sqlalchemy import create_engine, text
from urllib.parse import quote_plus
import pandas as pd

MYSQL_CONFIG = {
    'host': 'ow-masterdata-1.cavkqwqmyvuw.us-west-2.rds.amazonaws.com',
    'port': 3306,
    'database': 'ow_base',
    'user': 'ow_base_user',
    'password': '3we@5y_+05iu',
    'charset': 'utf8mb4',
    'autocommit': False,
    'connect_timeout': 30,
    'read_timeout': 60,
    'write_timeout': 60
}
TABLES = {
    'ASIN_goal_philips': 'ods_asin_goal_philips',
    'ods_category': 'ods_category',
    'ods_asin_philips': 'ods_asin_philips',
    'SI_keyword_philips': 'ods_si_keyword_philips',
    'ods_goal_vcp':'ods_goal_vcp',
    'ods_asin_sale_goal':'ods_asin_sale_goal',
    'ods_date_event': 'ods_date_even',
}
def get_engine():
    """åˆ›å»ºæ•°æ®åº“è¿æ¥"""
    #mysql+pymysql://root:password@localhost:3306/your_database
    password_encoded = quote_plus(MYSQL_CONFIG['password'])
    connection_string = f"mysql+pymysql://{MYSQL_CONFIG['user']}:{password_encoded}@{MYSQL_CONFIG['host']}:{MYSQL_CONFIG['port']}/{MYSQL_CONFIG['database']}?charset=utf8mb4"
    return create_engine(connection_string)

# åˆ—åè½¬å°å†™
def to_mysql_data(table_name, upload_mode, df, batch_size=1000):
    """ä¼˜åŒ–çš„åˆ†æ‰¹æ’å…¥ç‰ˆæœ¬"""
    try:
        to_mysql_data_safe(table_name, upload_mode, df)
        return True
    except Exception as e:
        print(f"å®‰å…¨æ’å…¥å¤±è´¥: {e}")

    engine = get_engine()
    table_name = TABLES[table_name]

    # å°†åˆ—åè½¬ä¸ºå°å†™
    df.columns = df.columns.str.lower()

    # å¤„ç†æ›¿æ¢æ¨¡å¼
    if upload_mode == 'replace':
        with engine.begin() as conn:
            try:
                conn.execute(text(f"TRUNCATE TABLE {table_name}"))
                print(f"å·²æ¸…ç©ºè¡¨ {table_name}")
            except Exception as e:
                print(f"TRUNCATEå¤±è´¥ï¼Œä½¿ç”¨DELETE: {e}")
                conn.rollback()
                conn.execute(text(f"DELETE FROM {table_name}"))

    # åˆ†æ‰¹æ’å…¥æ•°æ®
    total_rows = len(df)
    inserted = 0

    for i in range(0, total_rows, batch_size):
        batch_df = df.iloc[i:i + batch_size]

        try:
            # æ¯ä¸ªæ‰¹æ¬¡ä½¿ç”¨ç‹¬ç«‹çš„äº‹åŠ¡
            with engine.begin() as conn:
                # ä¸ºæ¯ä¸ªæ‰¹æ¬¡å•ç‹¬è®¾ç½®
                conn.execute(text("SET innodb_lock_wait_timeout = 300"))
                conn.execute(text("SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED"))

                batch_df.to_sql(
                    table_name,
                    engine,
                    if_exists='append',
                    index=False,
                    method=None
                )

            inserted += len(batch_df)
            print(f"å·²æ’å…¥ {inserted}/{total_rows} è¡Œ")

        except Exception as e:
            print(f"æ’å…¥ç¬¬{i}-{min(i + batch_size, total_rows) - 1}è¡Œæ—¶å¤±è´¥: {e}")
            raise

    print(f"æ•°æ®ä¸Šä¼ å®Œæˆï¼Œå…±æ’å…¥ {total_rows} è¡Œ")
    return True


def to_mysql_data_safe(table_name, upload_mode, df):
    """å®‰å…¨çš„æ‰¹é‡æ’å…¥ï¼Œé¿å…list of dictionariesé”™è¯¯"""
    engine = get_engine()
    table_name = TABLES[table_name]

    with engine.connect() as conn:
        # å¢åŠ é”ç­‰å¾…æ—¶é—´
        conn.execute(text("SET innodb_lock_wait_timeout = 300"))

        if upload_mode == 'replace':
            try:
                # å…ˆç¦ç”¨å¤–é”®æ£€æŸ¥
                conn.execute(text("SET FOREIGN_KEY_CHECKS = 0"))
                conn.execute(text(f"TRUNCATE TABLE {table_name}"))
                conn.execute(text("SET FOREIGN_KEY_CHECKS = 1"))
                print(f"å·²æ¸…ç©ºè¡¨: {table_name}")
            except Exception as e:
                print(f"TRUNCATEå¤±è´¥ï¼Œä½¿ç”¨DELETE: {e}")
                conn.rollback()
                conn.execute(text(f"DELETE FROM {table_name}"))

        # å°†åˆ—åè½¬ä¸ºå°å†™
        df.columns = df.columns.str.lower()

        # å‡†å¤‡æ’å…¥SQL
        columns = ', '.join(df.columns)
        placeholders = ', '.join(['%s'] * len(df.columns))
        sql = f"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})"

        # åˆ†æ‰¹æ’å…¥
        batch_size = 100
        data = [tuple(x) for x in df.itertuples(index=False, name=None)]
        total_rows = len(data)

        for i in range(0, total_rows, batch_size):
            batch_data = data[i:i + batch_size]

            try:
                # ä½¿ç”¨executemanyæ‰¹é‡æ’å…¥
                with conn.connection.cursor() as cursor:
                    cursor.executemany(sql, batch_data)
                    conn.connection.commit()

                print(f"âœ… å·²æ’å…¥ {min(i + batch_size, total_rows)}/{total_rows} è¡Œ")

            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡æ’å…¥å¤±è´¥: {e}")
                # å°è¯•å•è¡Œæ’å…¥
                for row_data in batch_data:
                    try:
                        with conn.connection.cursor() as cursor:
                            cursor.execute(sql, row_data)
                            conn.connection.commit()
                    except Exception as single_error:
                        print(f"å•è¡Œæ’å…¥å¤±è´¥: {single_error}")
                        continue

    print(f"ğŸ‰ æ•°æ®ä¸Šä¼ å®Œæˆï¼Œå…±æ’å…¥ {total_rows} è¡Œ")
    return True
